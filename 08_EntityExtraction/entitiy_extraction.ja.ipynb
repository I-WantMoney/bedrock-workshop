{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46fa37fd-e892-4504-ad32-edabb4760596",
   "metadata": {},
   "source": [
    "# Claude を用いたエンティティ抽出\n",
    "\n",
    "> *このノートブックは SageMaker Studio の **`Data Science 3.0`** カーネルで問題なく動作します。*\n",
    "\n",
    "### コンテキスト\n",
    "エンティティ抽出は、ニュース、電子メール、書籍などの自然に書かれたテキストから特定のデータを自動的に抽出できる NLP 手法です。\n",
    "そのデータは、後にデータベースに保存し、検索やその他の処理に使用することができます。\n",
    "\n",
    "従来のエンティティ抽出プログラムでは、通常、名前、住所、価格など、事前に定義済みのクラスに限定されるか、関心のあるエンティティの種類の例を多数提供する必要がありました。\n",
    "エンティティ抽出に LLM を使用すると、ほとんどの場合、抽出する必要があるものを自然言語で指定するだけで済みます。これにより、データのラベル付けが不要になるため、時間を節約しながら、クエリを柔軟かつ正確に行うことができます。\n",
    "\n",
    "さらに、LLM エンティティ抽出を使用すると、データセットを組み立てて、例えば [Amazon Comprehend のカスタムエンティティ](https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html) の認識など、後にユースケースに合わせてカスタマイズされたソリューションの作成が可能です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "373675b6-cdc4-437e-83b5-7d897516b8fc",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "このノートブックの残りの部分を実行する前に、以下のセルを実行して (必要なライブラリがインストールされていることを確認し) Bedrock に接続する必要があります。\n",
    "\n",
    "セットアップの仕組みや ⚠️ **変更が必要か**については,  [Bedrock boto3 setup](../00_Intro/bedrock_boto3_setup.ipynb) ノートブックを参照してください。\n",
    "\n",
    "このノートブックでは、いくつかの追加の依存関係も必要になります。:\n",
    "\n",
    "- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)を使うと、Claude のプロンプトと出力で、XML タグからデータを簡単に抽出できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\" \\\n",
    "    langchain==0.0.309 beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef0441-b424-403e-9394-d81b64e8332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock\n",
    "\n",
    "\n",
    "# ---- ⚠️ 必要に応じて AWS 設定に関する以下のコードのコメントを解除、編集してください  ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb9074b-d72e-4419-9165-421414d28f4b",
   "metadata": {},
   "source": [
    "## langchain の設定\n",
    "\n",
    "まず、LLM をインスタンス化します。ここでは、テキスト生成に Anthropic Claude v2 を使用しています。\n",
    "\n",
    "注意 : Bedrockでは他のモデルも選択可能です。`model_id` を以下のように置き換えてモデルを変更することができます。\n",
    "\n",
    "`llm = Bedrock(model_id=\"amazon.titan-tg1-large\")`\n",
    "\n",
    "使用可能なモデル ID には以下が含まれます:\n",
    "\n",
    "- `amazon.titan-tg1-large`\n",
    "- `ai21.j2-grande-instruct`\n",
    "- `ai21.j2-jumbo-instruct`\n",
    "- `anthropic.claude-instant-v1`\n",
    "- `anthropic.claude-v1`\n",
    "- `anthropic.claude-v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621790c0-332a-4bab-bf81-967a63cb52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 200,\n",
    "        \"temperature\": 0, # Using 0 to get reproducible results\n",
    "        \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f85e961-3530-4bf4-ac28-12611965d408",
   "metadata": {},
   "source": [
    "## エンティティ抽出\n",
    "LLM が初期化されたので、エンティティの抽出を開始できます。\n",
    "\n",
    "この演習では、質問や注文をメールで受け取るオンライン書店を想定します。\n",
    "私たちの仕事は、メールから関連情報を抽出し、注文を処理することです。\n",
    "\n",
    "まず、サンプルメールを見てみましょう。:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958f4c7-0ded-4537-9939-d1623337317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "emails_dir = Path(\".\") / \"emails\"\n",
    "with open(emails_dir / \"00_treasure_island.txt\") as f:\n",
    "    book_question_email = f.read()\n",
    "\n",
    "print(book_question_email)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f62564-cd46-4bff-bda3-c0f29a47dd9d",
   "metadata": {},
   "source": [
    "### 基本のアプローチ\n",
    "\n",
    "基本的なケースでは、モデルに直接結果を返すように依頼できます。\n",
    "本の名前を抽出してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc9062-64e9-4634-855c-d06ccb5efb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "\n",
    "Human: Given the email inside triple-backticks, please read it and analyse the contents.\n",
    "If a name of a book is mentioned, return it, otherwise return nothing.\n",
    "\n",
    "Email: ```\n",
    "{book_question_email}\n",
    "```\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742618e-25e9-441e-a6f8-b47330a0bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm(query)\n",
    "print(result.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e31a3407-caca-445a-bb1a-d62d40ddccd2",
   "metadata": {},
   "source": [
    "### モデル固有のプロンプト\n",
    "\n",
    "基本的な方法でも問題ありませんが、最良の結果を得るには、使用する特定のモデルに合わせてプロンプトをカスタマイズすることをお勧めします。\n",
    "今回の例では `anthropic.claude-v2`を使用しており、プロンプトガイドは[こちら](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)です。\n",
    "\n",
    "Claude v2　のより最適化されたプロンプトは次のとおりです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a461a9-4bad-4634-b568-a07769b1d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Human: Given the email provided, please read it and analyse the contents.\n",
    "If a name of a book is mentioned, return it.\n",
    "If no name is mentioned, return empty string.\n",
    "The email will be given between <email></email> XML tags.\n",
    "\n",
    "<email>\n",
    "{email}\n",
    "</email>\n",
    "\n",
    "Return the name of the book between <book></book> XML tags.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142cff9-c2d3-451e-8d21-06ce8538adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = prompt.format(email=book_question_email)\n",
    "result = llm(query)\n",
    "print(result.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e87ee5ab-33d9-4def-a462-8e5992032bd0",
   "metadata": {},
   "source": [
    "結果をより簡単に抽出するためには、補助関数を使うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9d2d0-2bc8-465c-b89b-73b2fd76d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_by_tag(response: str, tag: str, extract_all=False) -> str | list[str] | None:\n",
    "    soup = BeautifulSoup(response)\n",
    "    results = soup.find_all(tag)\n",
    "    if not results:\n",
    "        return\n",
    "        \n",
    "    texts = [res.get_text() for res in results]\n",
    "    if extract_all:\n",
    "        return texts\n",
    "    return texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7b280-71be-41ad-9f21-8c87d09226ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_by_tag(result, \"book\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f19454e6-22cd-41ee-888c-39801cc72c74",
   "metadata": {},
   "source": [
    "We can check that our model doesn't return arbitrary results when no appropriate information is given (also know as 'hallucination'), by running our prompt on other emails.\n",
    "\n",
    "他のメールにプロンプトを実行することで、適切な情報が与えられていない場合はモデルが任意の結果を返さないことを確認できます。（「ハルシネーション」とも呼ばれます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd1343-9b4b-4efd-846f-1312af18e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(emails_dir / \"01_return.txt\") as f:\n",
    "    return_email = f.read()\n",
    "\n",
    "print(return_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8a1b2-beb4-4ddf-9935-1fc7a3b08729",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = prompt.format(email=return_email)\n",
    "result = llm(query)\n",
    "print(result.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d154c270-41dc-4e58-bca2-f9fe5d021223",
   "metadata": {},
   "source": [
    "タグを使用すると、複数の情報を同時に抽出することもでき、抽出がより簡単になります。\n",
    "次のプロンプトでは、本の名前だけでなく、質問、要求、顧客名も抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b5c9b-b0c0-427d-a7fb-005253e9bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Human: Given email provided , please read it and analyse the contents.\n",
    "\n",
    "Please extract the following information from the email:\n",
    "- Any questions the customer is asking, return it inside <questions></questions> XML tags.\n",
    "- The customer full name, return it inside <name></name> XML tags.\n",
    "- Any book names the customer mentions, return it inside <books></books> XML tags.\n",
    "\n",
    "If a particular bit of information is not present, return an empty string.\n",
    "Make sure that each question can be understoon by itself, incorporate context if requred.\n",
    "Each returned question should be concise, remove extra information if possible.\n",
    "The email will be given between <email></email> XML tags.\n",
    "\n",
    "<email>\n",
    "{email}\n",
    "</email>\n",
    "\n",
    "Return each question inside <question></question> XML tags.\n",
    "Return the name of each book inside <book></book> XML tags.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac605eb5-2483-46ed-a205-6932051c8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = prompt.format(email=book_question_email)\n",
    "result = llm(query)\n",
    "print(result.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7cc2cb-8036-44a5-9fb6-db2172f9b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_by_tag(result, \"question\", extract_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5617e0d-0923-45b6-8e91-03748ad76d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_by_tag(result, \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66852eb2-97a2-4041-a76f-3fb03e1aaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_by_tag(result, \"book\", extract_all=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d830e149-5c89-4f50-9833-b499ee70f3f3",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "エンティティ抽出は、プレーンテキストの説明を使用して任意のデータを抽出することができる強力な手法です。\n",
    "\n",
    "これは、明確な構造を持たない特定のデータを抽出する必要がある場合に特に便利です。その場合は、正規表現やその他の従来の抽出手法を実装するのは非常に難しい場合があります。\n",
    "\n",
    "### 持ち帰り事項\n",
    "- このノートブックを変更し、Amazon Bedrock を通して Amazon Titan や AI21 Labs Jurassic モデルなどの様々なモデルを試してみましょう。\n",
    "- プロンプトを特定のユースケースに変更し、さまざまなモデルの出力を評価しましょう。\n",
    "- さまざまなプロンプトエンジニアリングの原則を適用して、より良い出力を得ましょう。推奨事項については、選択したモデルのプロンプトガイドを参照してください。例: Claude のプロンプトガイドは[こちら](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
