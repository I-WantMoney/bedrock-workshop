{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-tune Amazon Titan Text Express provided by Amazon Bedrock\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio. Also use ml.c5.2xlarge due to memory resources required*\n",
    "\n",
    "In this notebook, we will fine-tune [Amazon Titan Text Lite](#https://docs.aws.amazon.com/bedrock/latest/userguide/titan-text-models.html) model provided by Amazon Bedrock for summarization use case.\n",
    "You can choose from list of base models or fine-tune one of your previously fine tuned model.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " - Make sure you have executed `00_setup.ipynb` notebook.\n",
    " - Make sure you are using the same kernel and instance as `00_setup.ipynb` notebook.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> This notebook will create provisioned throughput for testing the fine-tuned model. Therefore, please make sure to delete the provisioned throughput as mentioned in the last section of the notebook, otherwise you will be charged for it, even if you are not using it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:14:35.373705Z",
     "start_time": "2024-04-25T15:13:59.834368Z"
    }
   },
   "source": [
    "!pip install -qU bert_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:14:41.228757Z",
     "start_time": "2024-04-25T15:14:41.220085Z"
    }
   },
   "source": [
    "# restart kernel for packages to take effect\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:15:04.873330Z",
     "start_time": "2024-04-25T15:15:04.846884Z"
    }
   },
   "source": [
    "## Fetching variables from `00_setup.ipynb` notebook. \n",
    "%store -r role_arn\n",
    "%store -r s3_train_uri\n",
    "%store -r s3_validation_uri\n",
    "%store -r s3_test_uri\n",
    "%store -r bucket_name"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:15:08.575228Z",
     "start_time": "2024-04-25T15:15:08.570563Z"
    }
   },
   "source": [
    "import pprint\n",
    "pprint.pp(role_arn)\n",
    "pprint.pp(s3_train_uri)\n",
    "pprint.pp(s3_validation_uri)\n",
    "pprint.pp(s3_test_uri)\n",
    "pprint.pp(bucket_name)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'arn:aws:iam::820537372947:role/BedrockRole-d6fec231-3d45-46fc-bb25-afc3fb4531ce'\n",
      "'s3://bedrock-customization-us-west-2-820537372947/fine-tuning-datasets/train/train-cnn-5K.jsonl'\n",
      "'s3://bedrock-customization-us-west-2-820537372947/fine-tuning-datasets/validation/validation-cnn-1K.jsonl'\n",
      "'s3://bedrock-customization-us-west-2-820537372947/fine-tuning-datasets/test/test-cnn-10.jsonl'\n",
      "'bedrock-customization-us-west-2-820537372947'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:15:20.726939Z",
     "start_time": "2024-04-25T15:15:20.548617Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:15:27.340131Z",
     "start_time": "2024-04-25T15:15:26.741724Z"
    }
   },
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sts_client = boto3.client('sts')\n",
    "s3_client = boto3.client('s3')\n",
    "aws_account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:15:31.281229Z",
     "start_time": "2024-04-25T15:15:31.278470Z"
    }
   },
   "source": [
    "test_file_name = \"test-cnn-10.jsonl\"\n",
    "data_folder = \"fine-tuning-datasets\""
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model you would like to fine-tune\n",
    "You will have to provide the `base_model_id` for the model you are planning to fine-tune. You can get that using `list_foundation_models` API as follows: \n",
    "```\n",
    "for model in bedrock.list_foundation_models(\n",
    "    byCustomizationType=\"FINE_TUNING\")[\"modelSummaries\"]:\n",
    "    for key, value in model.items():\n",
    "        print(key, \":\", value)\n",
    "    print(\"-----\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:15:58.773133Z",
     "start_time": "2024-04-25T15:15:58.770254Z"
    }
   },
   "source": [
    "base_model_id = \"amazon.titan-text-lite-v1:0:4k\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will need to provide the `customization_job_name`, `custom_model_name` and `customization_role` which will be used to create the fine-tuning job. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T15:16:13.572245Z",
     "start_time": "2024-04-25T15:16:13.568614Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "customization_job_name = f\"model-finetune-job-{ts}\"\n",
    "custom_model_name = f\"finetuned-model-{ts}\"\n",
    "customization_role = role_arn"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fine-tuning job\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Fine-tuning job will take around 40mins to complete.</div>\n",
    "\n",
    "Amazon Titan text model customization hyperparameters: \n",
    "- `epochs`: The number of iterations through the entire training dataset and can take up any integer values in the range of 1-10, with a default value of 5.\n",
    "- `batchSize`: The number of samples processed before updating model parameters and can take up any integer values in the range of 1-64, with a default value of 1.\n",
    "- `learningRate`:\tThe rate at which model parameters are updated after each batch\twhich can take up a float value between 0.0-1.0 with a default value set to\t1.00E-5.\n",
    "- `learningRateWarmupSteps`: The number of iterations over which the learning rate is gradually increased to the specified rate and can take any integer value between 0-250 with a default value of 5.\n",
    "\n",
    "For guidelines on setting hyper-parameters refer to the guidelines provided [here](#https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-guidelines.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T16:08:53.260419Z",
     "start_time": "2024-04-25T16:08:53.255046Z"
    }
   },
   "source": [
    "# Select the customization type from \"FINE_TUNING\" or \"CONTINUED_PRE_TRAINING\". \n",
    "customization_type = \"FINE_TUNING\""
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T16:09:01.292422Z",
     "start_time": "2024-04-25T16:09:00.782400Z"
    }
   },
   "source": [
    "# Define the hyperparameters for fine-tuning Titan text model\n",
    "hyper_parameters = {\n",
    "        \"epochCount\": \"2\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.00003\",\n",
    "    }\n",
    "\n",
    "\n",
    "s3_bucket_config=f's3://{bucket_name}/outputs/output-{custom_model_name}'\n",
    "# Specify your data path for training, validation(optional) and output\n",
    "training_data_config = {\"s3Uri\": s3_train_uri}\n",
    "\n",
    "validation_data_config = {\n",
    "        \"validators\": [{\n",
    "            # \"name\": \"validation\",\n",
    "            \"s3Uri\": s3_validation_uri\n",
    "        }]\n",
    "    }\n",
    "\n",
    "output_data_config = {\"s3Uri\": s3_bucket_config}\n",
    "\n",
    "\n",
    "# Create the customization job\n",
    "training_job_response = bedrock.create_model_customization_job(\n",
    "    customizationType=customization_type,\n",
    "    jobName=customization_job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=customization_role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters=hyper_parameters,\n",
    "    trainingDataConfig=training_data_config,\n",
    "    validationDataConfig=validation_data_config,\n",
    "    outputDataConfig=output_data_config\n",
    ")\n",
    "training_job_response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '46062495-86e5-4fc7-8e23-9b8526cf5021',\n",
       "  'HTTPStatusCode': 201,\n",
       "  'HTTPHeaders': {'date': 'Thu, 25 Apr 2024 16:09:01 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '119',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '46062495-86e5-4fc7-8e23-9b8526cf5021'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:820537372947:model-customization-job/amazon.titan-text-lite-v1:0:4k/6bax26l8mpid'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check fine-tuning job status"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T18:25:47.647386Z",
     "start_time": "2024-04-25T16:09:13.115166Z"
    }
   },
   "source": [
    "# This job took nearly an hour to complete\n",
    "fine_tune_job = bedrock.get_model_customization_job(jobIdentifier=customization_job_name)[\"status\"]\n",
    "print(fine_tune_job)\n",
    "\n",
    "while fine_tune_job == \"InProgress\":\n",
    "    time.sleep(60)\n",
    "    fine_tune_job = bedrock.get_model_customization_job(jobIdentifier=customization_job_name)[\"status\"]\n",
    "    print (fine_tune_job)\n",
    "    time.sleep(60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:21:49.562625Z",
     "start_time": "2024-04-25T19:21:49.090589Z"
    }
   },
   "source": [
    "fine_tune_job = bedrock.get_model_customization_job(jobIdentifier=customization_job_name)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:21:50.589612Z",
     "start_time": "2024-04-25T19:21:50.582167Z"
    }
   },
   "source": [
    "pprint.pp(fine_tune_job)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '4afb6c91-0cc5-4a73-8f7d-7c55fcb85784',\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'HTTPHeaders': {'date': 'Thu, 25 Apr 2024 19:21:49 GMT',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'content-length': '1429',\n",
      "                                      'connection': 'keep-alive',\n",
      "                                      'x-amzn-requestid': '4afb6c91-0cc5-4a73-8f7d-7c55fcb85784'},\n",
      "                      'RetryAttempts': 0},\n",
      " 'jobArn': 'arn:aws:bedrock:us-west-2:820537372947:model-customization-job/amazon.titan-text-lite-v1:0:4k/6bax26l8mpid',\n",
      " 'jobName': 'model-finetune-job-2024-04-25-10-16-13',\n",
      " 'outputModelName': 'finetuned-model-2024-04-25-10-16-13',\n",
      " 'outputModelArn': 'arn:aws:bedrock:us-west-2:820537372947:custom-model/amazon.titan-text-lite-v1:0:4k/dkem5a27nhkt',\n",
      " 'clientRequestToken': 'ff786a98-3f79-4d57-95ac-84a07e3ab2cf',\n",
      " 'roleArn': 'arn:aws:iam::820537372947:role/BedrockRole-d6fec231-3d45-46fc-bb25-afc3fb4531ce',\n",
      " 'status': 'Completed',\n",
      " 'creationTime': datetime.datetime(2024, 4, 25, 16, 9, 1, 254000, tzinfo=tzutc()),\n",
      " 'lastModifiedTime': datetime.datetime(2024, 4, 25, 18, 22, 59, 63000, tzinfo=tzutc()),\n",
      " 'endTime': datetime.datetime(2024, 4, 25, 18, 22, 58, 613000, tzinfo=tzutc()),\n",
      " 'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
      " 'hyperParameters': {'batchSize': '1',\n",
      "                     'epochCount': '2',\n",
      "                     'learningRate': '0.00003',\n",
      "                     'learningRateWarmupSteps': '5'},\n",
      " 'trainingDataConfig': {'s3Uri': 's3://bedrock-customization-us-west-2-820537372947/fine-tuning-datasets/train/train-cnn-5K.jsonl'},\n",
      " 'validationDataConfig': {'validators': [{'s3Uri': 's3://bedrock-customization-us-west-2-820537372947/fine-tuning-datasets/validation/validation-cnn-1K.jsonl'}]},\n",
      " 'outputDataConfig': {'s3Uri': 's3://bedrock-customization-us-west-2-820537372947/outputs/output-finetuned-model-2024-04-25-10-16-13'},\n",
      " 'customizationType': 'FINE_TUNING',\n",
      " 'validationMetrics': []}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:21:52.425324Z",
     "start_time": "2024-04-25T19:21:52.418065Z"
    }
   },
   "source": [
    "output_job_name = \"model-customization-job-\"+fine_tune_job['jobArn'].split('/')[-1]\n",
    "output_job_name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model-customization-job-6bax26l8mpid'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create [`provisioned throughput`](#) which is needed before you can do the inference on the fine-tuned model.\n",
    "\n",
    "### Overview of Provisioned throughput\n",
    "You specify Provisioned Throughput in Model Units (MU). A model unit delivers a specific throughput level for the specified model. The throughput level of a MU for a given Text model specifies the following:\n",
    "\n",
    "- The total number of input tokens per minute – The number of input tokens that an MU can process across all requests within a span of one minute.\n",
    "\n",
    "- The total number of output tokens per minute – The number of output tokens that an MU can generate across all requests within a span of one minute.\n",
    "\n",
    "Model unit quotas depend on the level of commitment you specify for the Provisioned Throughput.\n",
    "\n",
    "- For custom models with no commitment, a quota of one model unit is available for each Provisioned Throughput. You can create up to two Provisioned Throughputs per account.\n",
    "\n",
    "- For base or custom models with commitment, there is a default quota of 0 model units. To request an increase, use the [limit increase form](#https://support.console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Custom Model\n",
    "Once the customization job is finished, you can check your existing custom model(s) and retrieve the modelArn of your fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:22:08.052968Z",
     "start_time": "2024-04-25T19:22:07.896093Z"
    }
   },
   "source": [
    "# List your custom models\n",
    "bedrock.list_custom_models()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'bea80389-f678-4090-9824-311d44acfb3b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 25 Apr 2024 19:22:08 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '385',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'bea80389-f678-4090-9824-311d44acfb3b'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2:820537372947:custom-model/amazon.titan-text-lite-v1:0:4k/dkem5a27nhkt',\n",
       "   'modelName': 'finetuned-model-2024-04-25-10-16-13',\n",
       "   'creationTime': datetime.datetime(2024, 4, 25, 16, 9, 1, 254000, tzinfo=tzutc()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
       "   'baseModelName': '',\n",
       "   'customizationType': 'FINE_TUNING'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:22:17.922010Z",
     "start_time": "2024-04-25T19:22:17.713030Z"
    }
   },
   "source": [
    "model_id = bedrock.get_custom_model(modelIdentifier=custom_model_name)['modelArn']\n",
    "model_id"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2:820537372947:custom-model/amazon.titan-text-lite-v1:0:4k/dkem5a27nhkt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Provisioned Throughput\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Creating provisioned throughput will take around 20-30mins to complete.</div>\n",
    "\n",
    "You will need to create provisioned throughput to be able to evaluate the model performance. You can do so through the [console].(https://docs.aws.amazon.com/bedrock/latest/userguide/prov-cap-console.html) or use the following api call:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:22:49.222736Z",
     "start_time": "2024-04-25T19:22:48.482652Z"
    }
   },
   "source": [
    "import boto3 \n",
    "boto3.client(service_name='bedrock')\n",
    "provisioned_model_id = bedrock.create_provisioned_model_throughput(\n",
    " modelUnits=1,\n",
    " provisionedModelName='test-model', \n",
    " modelId=model_id\n",
    ")['provisionedModelArn']     "
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:22:49.864034Z",
     "start_time": "2024-04-25T19:22:49.693367Z"
    }
   },
   "source": [
    "status_provisioning = bedrock.get_provisioned_model_throughput(provisionedModelId = provisioned_model_id)['status']"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:34:54.157616Z",
     "start_time": "2024-04-25T19:22:50.696456Z"
    }
   },
   "source": [
    "import time\n",
    "while status_provisioning == 'Creating':\n",
    "    time.sleep(60)\n",
    "    status_provisioning = bedrock.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id)['status']\n",
    "    print(status_provisioning)\n",
    "    time.sleep(60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the Custom Model\n",
    "\n",
    "Before invoking, let's get a sample prompt from our test data. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:40:37.135928Z",
     "start_time": "2024-04-25T19:40:37.131026Z"
    }
   },
   "source": [
    "# Provide the prompt text \n",
    "test_file_path = f'{data_folder}/{test_file_name}'\n",
    "with open(test_file_path) as f:\n",
    "    lines = f.read().splitlines()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:40:39.614232Z",
     "start_time": "2024-04-25T19:40:39.609627Z"
    }
   },
   "source": [
    "test_prompt = json.loads(lines[3])['prompt']\n",
    "reference_summary = json.loads(lines[3])['completion']\n",
    "pprint.pp(test_prompt)\n",
    "print(reference_summary)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Below is an instruction that describes a task, paired with an input that '\n",
      " 'provides further context. Write a response that appropriately completes the '\n",
      " 'request.\\n'\n",
      " '\\n'\n",
      " 'instruction:\\n'\n",
      " '\\n'\n",
      " 'Summarize the news article provided below.\\n'\n",
      " '\\n'\n",
      " 'input:\\n'\n",
      " '\\n'\n",
      " \"Sachin Tendulkar has paid tribute to a 'promising' Indian cricketer who has \"\n",
      " 'died after colliding with a team-mate while attempting to take a catch '\n",
      " 'during a club match in Kolkata. The Board of Control for Cricket In India '\n",
      " 'confirmed on their official Twitter account that 20-year-old Ankit Keshri '\n",
      " \"had passed away after suffering 'a cardiac arrest following on-field \"\n",
      " \"injury'. According to reports, Keshri colleded with a team-mate as they both \"\n",
      " 'attempted to take a catch in a senior one-day match match in Kolkata on '\n",
      " 'Friday, and though he regained consciousness afterwards, he died in hospital '\n",
      " 'on Monday. Keshri was only playing as a substitute fielder having been the '\n",
      " '12th man. Ankit Keshri had passed away after suffering a cardiac arrest '\n",
      " 'following an on-field injury in Kolkata . Former national team captain '\n",
      " 'Tendulkar, the highest runscorer in Test and one-day international history, '\n",
      " 'was among several India stars to offer their condolences at the news. '\n",
      " \"Tendulkar tweeted: 'Saddened by the demise of Ankit Keshri. A promising \"\n",
      " \"career aborted by an unfortunate incident on field. 'May God give strength \"\n",
      " \"to Ankit's family and friends to cope with this loss #RIP' Current India \"\n",
      " \"batsman Ajinkya Rahane said: 'Very sad to know about Ankit Keshri. Strength \"\n",
      " \"to his family and friends. RIP.' Manoj Tiwary, who has played nine ODIs for \"\n",
      " \"India, wrote: 'I'm shocked 2 hear d news of Under-19 player from bengal \"\n",
      " \"named Ankit kesri's demise due to heart attack. My deepest condolences goes \"\n",
      " \"out 2 Ankit kesri's family nd frnds. 'A promising player who scored loads of \"\n",
      " 'runs at under 19 level nd he wud hav surely played 4 senior bengal in 2 '\n",
      " \"years time. Rest in peace younger brother.' The 20-year-old\\xa0died after \"\n",
      " 'colliding with a team-mate while attempting to take a catch during a club '\n",
      " 'match . The tragedy comes five months after Australia batsman Phillip Hughes '\n",
      " 'died aged 25 after being hit on the neck by a bouncer in a Sheffield Shield '\n",
      " 'match. Keshri was considered an up-and-coming talent on the Indian cricket '\n",
      " 'scene. The right-hander was captain of the Bengal Under-19 team, and was '\n",
      " \"short-listed for India's under-19 team for the 2014 Colts World Cup. 'It's \"\n",
      " \"so unfortunate,' said the Bengal cricket association's Subir Ganguly. 'He \"\n",
      " 'was such a promising cricketer and for him to pass away in such a manner is '\n",
      " \"difficult to swallow.' India cricket legend Sachin Tendulkar is among \"\n",
      " 'several stars to have given tributes about\\xa0Keshri .')\n",
      "response:\n",
      "\n",
      "Ankit Keshri was on the pitch  as a substitute fielder having been 12th man .\n",
      "20-year-old did regain consciousness after colliding with team-mate .\n",
      "Sachin Tendulkar is one of several stars to give his condolences .\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:42:31.454896Z",
     "start_time": "2024-04-25T19:42:31.450532Z"
    }
   },
   "source": [
    "prompt = f\"\"\"\n",
    "{test_prompt}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:42:35.738423Z",
     "start_time": "2024-04-25T19:42:35.734501Z"
    }
   },
   "source": [
    "base_model_arn = f'arn:aws:bedrock:{region}::foundation-model/amazon.titan-text-lite-v1'"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to construct model input following the format needed by titan text model following instructions [here](#https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-text.html). \n",
    "Please pay attention to the \"Model invocation request body field\" section in the `body` variable, which we will pass as payload to the custom model trained above. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:42:57.989069Z",
     "start_time": "2024-04-25T19:42:52.752055Z"
    }
   },
   "source": [
    "body = json.dumps(\n",
    "    {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 2048,\n",
    "        \"stopSequences\": ['User:'],\n",
    "        \"temperature\": 0,\n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "    }\n",
    "        )\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "fine_tuned_response = bedrock_runtime.invoke_model(body=body, \n",
    "                                        modelId=provisioned_model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)\n",
    "\n",
    "base_model_response = bedrock_runtime.invoke_model(body=body, \n",
    "                                        modelId=base_model_arn, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)\n",
    "\n",
    "fine_tuned_response_body = json.loads(fine_tuned_response.get('body').read())\n",
    "base_model_response_body = json.loads(base_model_response.get('body').read())\n",
    "\n",
    "print(\"Base model response: \", base_model_response_body[\"results\"][0][\"outputText\"] + '\\n')\n",
    "print(\"Fine tuned model response:\", fine_tuned_response_body[\"results\"][0][\"outputText\"]+'\\n')\n",
    "print(\"Reference summary from test data: \", reference_summary)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model response:  Ankit Keshri, 20, died after suffering a cardiac arrest following an on-field injury .\n",
      "Keshri was playing as a substitute fielder having been the 12th man .\n",
      "Tendulkar, Rahane and Manoj Tiwary among those to have given tributes .\n",
      "\n",
      "Fine tuned model response: Ankit Keshri, 20, died after suffering a cardiac arrest following an on-field injury.\n",
      "The right-hander was playing for a club side in Kolkata when he died.\n",
      "Tendulkar, Ajinkya Rahane and Manoj Tiwary among those to have given tributes.\n",
      "\n",
      "Reference summary from test data:  response:\n",
      "\n",
      "Ankit Keshri was on the pitch  as a substitute fielder having been 12th man .\n",
      "20-year-old did regain consciousness after colliding with team-mate .\n",
      "Sachin Tendulkar is one of several stars to give his condolences .\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance of the model\n",
    "<!--we should use Bedrock's model evaulation feature to compare the model performance-->\n",
    "In this section, we will use `BertScore` metrics  to evaluate the performance of the fine-tuned model as compared to base model to check if fine-tuning has improved the results.\n",
    "\n",
    "- `BERTScore`: calculates the similarity between a summary and reference texts based on the outputs of BERT (Bidirectional Encoder Representations from Transformers), a powerful language model. [Medium article link](#https://haticeozbolat17.medium.com/bertscore-and-rouge-two-metrics-for-evaluating-text-summarization-systems-6337b1d98917)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:44:08.636964Z",
     "start_time": "2024-04-25T19:44:08.633352Z"
    }
   },
   "source": [
    "base_model_generated_response = [base_model_response_body[\"results\"][0][\"outputText\"]]\n",
    "fine_tuned_generated_response = [fine_tuned_response_body[\"results\"][0][\"outputText\"]]"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:53:34.675882Z",
     "start_time": "2024-04-25T19:53:28.301730Z"
    }
   },
   "source": [
    "from bert_score import score\n",
    "reference_summary = [reference_summary]\n",
    "fine_tuned_model_P, fine_tuned_R, fine_tuned_F1 = score(fine_tuned_generated_response, reference_summary, lang=\"en\")\n",
    "base_model_P, base_model_R, base_model_F1 = score(base_model_generated_response, reference_summary, lang=\"en\")\n",
    "print(\"F1 score: base model \", base_model_F1)\n",
    "print(\"F1 score: fine-tuned model\", fine_tuned_F1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: base model  tensor([0.8868])\n",
      "F1 score: fine-tuned model tensor([0.8532])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "From the scores above and looking at the base model summary, fine-tuned model summary and reference summary, it clearly indicates that fine-tuning the model tends to improve the results on the task it's trained on. We only used 1K records with 100 validation records and 2 epochs, and were able to get better results. \n",
    "You may want to adjust the `learning_rate` first, then visualize training and validation metrics to understand the performance of training job, before increase the size of your data. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> \n",
    "    Please refer to the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-guidelines.html\" style=\"color: #3372FF\">guidelines </a> provided for fine-tuning the model based on your task. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete provisioned throughput\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Please make sure to delete provisioned throughput as there will cost incurred if its left in running state, even if you are not using it. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T19:59:43.667015Z",
     "start_time": "2024-04-25T19:59:42.431059Z"
    }
   },
   "source": [
    "bedrock.delete_provisioned_model_throughput(provisionedModelId=provisioned_model_id)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '39986c35-91d0-4b1a-980a-d53eb4c3131d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 25 Apr 2024 19:59:43 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '39986c35-91d0-4b1a-980a-d53eb4c3131d'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
