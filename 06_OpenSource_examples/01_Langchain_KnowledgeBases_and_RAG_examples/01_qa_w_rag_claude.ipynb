{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Question & Answering with Amazon Bedrock using LangChain\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "Previously we saw that the model told us how to change a tire, however, we had to manually provide it with the relevant data and provide the context ourselves. We explored an approach that leveraged a model available under Bedrock and asked it questions based on the knowledge it acquired during training as well as providing additional context. That approach works with short documents or single-ton applications, but it fails to scale to enterprise-level question answering where there could be large enterprise documents which cannot fit into the model's context window. \n",
    "\n",
    "### Pattern\n",
    "We can improve upon this process by implementing an architecture called Retrieval Augmented Generation (RAG). RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. \n",
    "\n",
    "In this notebook we explain how to approach the pattern of Question Answering to find and leverage the documents to provide answers to the user questions.\n",
    "\n",
    "### Challenges\n",
    "- How to manage large document(s) that exceed the token limit\n",
    "- How to find the document(s) relevant to the question being asked\n",
    "\n",
    "### Proposal\n",
    "To the above challenges, this notebook proposes the following strategy\n",
    "#### Prepare documents\n",
    "![Embeddings](./images/Embeddings_lang.png)\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and a stored in a document store index\n",
    "- Load the documents\n",
    "- Process and split them into smaller chunks\n",
    "- Create a numerical vector representation of each chunk using Amazon Bedrock Titan Embeddings model\n",
    "- Create an index using the chunks and the corresponding embeddings\n",
    "#### Ask question\n",
    "![Question](./images/Chatbot_lang.png)\n",
    "\n",
    "Once the document index is prepared, you can start asking the model questions and it will fetch the relevant documents based on the question being asked. The following steps will be executed:\n",
    "- Create an embedding of the input question\n",
    "- Compare the question embedding with the embeddings in the index\n",
    "- Fetch the (top N) relevant document chunks\n",
    "- Add those chunks as part of the context in the prompt\n",
    "- Send the prompt to the model under Amazon Bedrock\n",
    "- Get the contextual answer based on the documents retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case\n",
    "#### Dataset\n",
    "To explain this architecture pattern we are using the documents from IRS. These documents explain topics such as:\n",
    "- Original Issue Discount (OID) Instruments\n",
    "- Reporting Cash Payments of Over $10,000 to IRS\n",
    "- Employer's Tax Guide\n",
    "\n",
    "#### Persona\n",
    "Let's assume the persona of a layman who doesn\\'t have an understanding of how the IRS works and if some actions have implications or not.\n",
    "\n",
    "The model will try to answer from the documents in human friendly language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "In order to follow the RAG approach, this notebook is using the LangChain framework where it has integrations with different services and tools that allow to build efficient patterns such as RAG. We will be using the following tools:\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude v2 available through Amazon Bedrock\n",
    "\n",
    "  This model will be used to understand the document chunks and provide an answer in human friendly manner.\n",
    "- **Embeddings Model**: Amazon Titan Embeddings available through Amazon Bedrock\n",
    "\n",
    "  This model will be used to generate a numerical representation of the textual documents\n",
    "- **Document Loader**: PDF Loader available through LangChain\n",
    "\n",
    "  This is the loader that can load the documents from a source, for the sake of this notebook we are loading the sample files from a local path. This could easily be replaced with a loader to load documents from enterprise internal systems.\n",
    "\n",
    "- **Vector Store**: FAISS available through LangChain\n",
    "\n",
    "  In this notebook we are using this in-memory vector-store to store both the embeddings and the documents. In an enterprise context this could be replaced with a persistent store such as AWS OpenSearch, RDS Postgres with pgVector, ChromaDB, Pinecone or Weaviate.\n",
    "- **Index**: VectorIndex\n",
    "\n",
    "  The index helps to compare the input embedding and the document embeddings to find relevant document\n",
    "- **Wrapper**: wraps index, vector store, embeddings model and the LLM to abstract away the logic from the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "⚠️ ⚠️ ⚠️ Before running this notebook, ensure you've run the [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb#Prerequisites) notebook. ⚠️ ⚠️ ⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:37:15.247614Z",
     "start_time": "2024-05-01T18:37:15.237773Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:41:15.503669Z",
     "start_time": "2024-05-01T18:41:03.889078Z"
    }
   },
   "source": [
    "%pip install langchain>=0.1.11\n",
    "%pip install langchain-aws==0.1.0\n",
    "%pip install pypdf==4.1.0\n",
    "%pip install langchain-community faiss-cpu==1.8.0 tiktoken==0.6.0 sqlalchemy==2.0.28\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 0.1.11 not found\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-aws==0.1.0\r\n",
      "  Using cached langchain_aws-0.1.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.72 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-aws==0.1.0) (1.34.94)\r\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-aws==0.1.0) (0.1.46)\r\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.94 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from boto3<2.0.0,>=1.34.72->langchain-aws==0.1.0) (1.34.94)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from boto3<2.0.0,>=1.34.72->langchain-aws==0.1.0) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from boto3<2.0.0,>=1.34.72->langchain-aws==0.1.0) (0.10.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (0.1.51)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (2.7.1)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (8.2.3)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.94->boto3<2.0.0,>=1.34.72->langchain-aws==0.1.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.94->boto3<2.0.0,>=1.34.72->langchain-aws==0.1.0) (2.2.1)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (3.10.1)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (2.31.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (2.18.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (4.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.94->boto3<2.0.0,>=1.34.72->langchain-aws==0.1.0) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (3.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-aws==0.1.0) (2024.2.2)\r\n",
      "Using cached langchain_aws-0.1.0-py3-none-any.whl (32 kB)\r\n",
      "Installing collected packages: langchain-aws\r\n",
      "  Attempting uninstall: langchain-aws\r\n",
      "    Found existing installation: langchain-aws 0.1.2\r\n",
      "    Uninstalling langchain-aws-0.1.2:\r\n",
      "      Successfully uninstalled langchain-aws-0.1.2\r\n",
      "Successfully installed langchain-aws-0.1.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pypdf==4.1.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (4.1.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-community in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (0.0.34)\r\n",
      "Requirement already satisfied: faiss-cpu==1.8.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (1.8.0)\r\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (0.6.0)\r\n",
      "Requirement already satisfied: sqlalchemy==2.0.28 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (2.0.28)\r\n",
      "Requirement already satisfied: numpy in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from faiss-cpu==1.8.0) (1.24.4)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from tiktoken==0.6.0) (2024.4.16)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from tiktoken==0.6.0) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from sqlalchemy==2.0.28) (4.11.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from sqlalchemy==2.0.28) (3.0.3)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-community) (6.0.1)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-community) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-community) (0.6.4)\r\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.45 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-community) (0.1.46)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-community) (0.1.51)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-community) (8.2.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.45->langchain-community) (1.33)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.45->langchain-community) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.45->langchain-community) (2.7.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (2024.2.2)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain-community) (2.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain-community) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain-community) (2.18.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jicowan/PycharmProjects/amazon-bedrock-workshop/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:37:44.376532Z",
     "start_time": "2024-05-01T18:37:43.944739Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:38:39.710837Z",
     "start_time": "2024-05-01T18:38:39.706487Z"
    }
   },
   "source": [
    "import warnings\n",
    "\n",
    "from io import StringIO\n",
    "import sys\n",
    "import textwrap\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def print_ww(*args, width: int = 100, **kwargs):\n",
    "    \"\"\"Like print(), but wraps output to `width` characters (default 100)\"\"\"\n",
    "    buffer = StringIO()\n",
    "    try:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        print(*args, **kwargs)\n",
    "        output = buffer.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = _stdout\n",
    "    for line in output.splitlines():\n",
    "        print(\"\\n\".join(textwrap.wrap(line, width=width)))\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure LangChain\n",
    "\n",
    "We begin by instantiating the LLM and the Embeddings model. Here we are using Anthropic Claude for text generation and Amazon Titan for text embedding.\n",
    "\n",
    "Note: It is possible to choose other models available with Bedrock. You can replace the `model_id` as follows to change the model.\n",
    "\n",
    "`llm = Bedrock(model_id=\"amazon.titan-text-express-v1\")`\n",
    "\n",
    "Check [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html) for the text generation and embedding models Ids available under Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:46:46.190199Z",
     "start_time": "2024-05-01T18:46:40.022347Z"
    }
   },
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = BedrockLLM(model_id=\"anthropic.claude-v2\", model_kwargs={'max_tokens_to_sample':200})\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=boto3_bedrock)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's download some of the files to build our document store. For this example, we will be using public IRS documents from [here](https://www.irs.gov/publications)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:47:21.941770Z",
     "start_time": "2024-05-01T18:47:20.654615Z"
    }
   },
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1544.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p15.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1212.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the files, we can load the documents with the help of [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html) and splitting them into smaller chunks.\n",
    "\n",
    "Note: The retrieved document/text should be large enough to contain enough information to answer a question; but small enough to fit into the LLM prompt. Also, the embeddings model has a limit of the length of input tokens limited to 8192 tokens, which roughly translates to ~32,000 characters. For the sake of this use-case, we are creating chunks of roughly 1000 characters with an overlap of 100 characters using [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:48:52.526976Z",
     "start_time": "2024-05-01T18:48:48.331799Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:48:57.920509Z",
     "start_time": "2024-05-01T18:48:57.912046Z"
    }
   },
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n",
    "avg_char_count_pre = avg_doc_length(documents)\n",
    "avg_char_count_post = avg_doc_length(docs)\n",
    "print(f'Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.')\n",
    "print(f'After the split we have {len(docs)} documents more than the original {len(documents)}.')\n",
    "print(f'Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 81 documents loaded is 5889 characters.\n",
      "After the split we have 560 documents more than the original 81.\n",
      "Average length among 560 documents (after split) is 912 characters.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 3 PDF documents which have been split into smaller ~500 chunks.\n",
    "\n",
    "Now we can see how a sample embedding would look like for one of those chunks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:50:59.208752Z",
     "start_time": "2024-05-01T18:50:58.385159Z"
    }
   },
   "source": [
    "try:\n",
    "    sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n",
    "    print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "    print(\"Size of the embedding: \", sample_embedding.shape)\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubleshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [ 0.11621094  0.06494141 -0.23730469 ...  0.11962891 -0.29882812\n",
      " -0.27929688]\n",
      "Size of the embedding:  (1536,)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the similar pattern, embeddings could be generated for the entire corpus and stored in a vector store.\n",
    "\n",
    "This can be easily done by implementing [FAISS](https://github.com/facebookresearch/faiss) inside [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html) which takes the input from the embeddings model and the documents to create the entire vector store. Using the Index Wrapper we can abstract away most of the heavy lifting such as creating the prompt, getting embeddings of the query, sampling the relevant documents and calling the LLM. [VectorStoreIndexWrapper](https://python.langchain.com/en/latest/modules/indexes/getting_started.html#one-line-index-creation) helps us with that.\n",
    "\n",
    "**⚠️⚠️⚠️ NOTE: it might take few minutes to run the following cell ⚠️⚠️⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:55:57.316979Z",
     "start_time": "2024-05-01T18:53:31.236730Z"
    }
   },
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "\n",
    "vectorstore_faiss = FAISS.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings,\n",
    ")\n",
    "\n",
    "wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "Now that we have our vector store in place, we can start asking questions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:59:24.201056Z",
     "start_time": "2024-05-01T18:59:24.197917Z"
    }
   },
   "source": "query = \"\"\"Will I go to jail if I fail to file my taxes?\"\"\"",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step would be to create an embedding of the query such that it could be compared with the documents"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T18:59:26.097229Z",
     "start_time": "2024-05-01T18:59:25.922239Z"
    }
   },
   "source": [
    "query_embedding = vectorstore_faiss.embedding_function.embed_query(query)\n",
    "np.array(query_embedding)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01953125,  0.08544922, -0.15917969, ..., -0.12695312,\n",
       "       -0.64453125, -0.28320312])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this embedding of the query to fetch the relevant documents.\n",
    "Now our query is represented as embeddings we can do a similarity search of our query against our data store providing us with the most relevant information."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:00:01.534844Z",
     "start_time": "2024-05-01T19:00:01.514751Z"
    }
   },
   "source": [
    "relevant_documents = vectorstore_faiss.similarity_search_by_vector(query_embedding)\n",
    "print(f'{len(relevant_documents)} documents are fetched which are relevant to the query.')\n",
    "print('----')\n",
    "for i, rel_doc in enumerate(relevant_documents):\n",
    "    print_ww(f'## Document {i+1}: {rel_doc.page_content}.......')\n",
    "    print('---')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents are fetched which are relevant to the query.\n",
      "----\n",
      "## Document 1: There are civil penalties for failure to:\n",
      "File a correct Form 8300 by the date it is\n",
      "due, and\n",
      "Provide the required statement to those\n",
      "named in the Form 8300.\n",
      "If you intentionally disregard the requirement\n",
      "to file a correct Form 8300 by the date it is due,\n",
      "the penalty is the greater of:\n",
      "1.$25,000, or\n",
      "2.The amount of cash you received and\n",
      "were required to report (up to $100,000).\n",
      "There are criminal penalties for:\n",
      "Willful failure to file Form 8300,\n",
      "Willfully filing a false or fraudulent Form\n",
      "8300,\n",
      "Stopping or trying to stop Form 8300 from\n",
      "being filed, and\n",
      "Setting up, helping to set up, or trying to\n",
      "set up a transaction in a way that would\n",
      "make it seem unnecessary to file Form\n",
      "8300.\n",
      "If you willfully fail to file Form 8300, you can\n",
      "be fined up to $250,000 for individuals\n",
      "RECORDS($500,000 for corporations) or sentenced to up\n",
      "to 5 years in prison, or both. These dollar\n",
      "amounts are based on Section 3571 of Title 18\n",
      "of the U.S. Code........\n",
      "---\n",
      "## Document 2: ure-to- pay (FTP) penalty of 0.5% per month of the amount\n",
      "of tax. For individual filers only, the FTP penalty is reduced\n",
      "from 0.5% per month to 0.25% per month if an installment\n",
      "agreement is in effect. Y ou must have filed your return on\n",
      "or before the due date of the return to qualify for the re-\n",
      "duced penalty. The maximum amount of the FTP penalty\n",
      "is also 25% of the tax due. If both penalties apply in any\n",
      "month, the FTF penalty is reduced by the amount of the\n",
      "FTP penalty. The penalties won't be charged if you have\n",
      "reasonable cause for failing to file or pay. If you receive a\n",
      "penalty notice, you can provide an explanation of why you\n",
      "believe reasonable cause exists.\n",
      "Note.  In addition to any penalties, interest accrues\n",
      "from the due date of the tax on any unpaid balance.\n",
      "If income, social security, or Medicare taxes that must\n",
      "be withheld aren't withheld or aren't paid, you may be per-\n",
      "sonally liable for the trust fund recovery penalty. See T rust.......\n",
      "---\n",
      "## Document 3: the exceptions to the deposit requirements discussed un-\n",
      "der Payment with return , earlier in this section).\n",
      "Penalties may apply if you don't make required deposits\n",
      "on time or if you make deposits for less than the required\n",
      "amount. The penalties don't apply if any failure to make a\n",
      "proper and timely deposit was due to reasonable cause\n",
      "and not to willful neglect. If you receive a penalty notice,\n",
      "you can provide an explanation of why you believe reason-\n",
      "able cause exists.\n",
      "If you timely filed your employment tax return, the IRS\n",
      "may also waive deposit penalties if you inadvertently failed\n",
      "to deposit and it was the first quarter that you were re-\n",
      "quired to deposit any employment tax, or if you inadver-\n",
      "tently failed to deposit the first time after your deposit fre-\n",
      "quency changed. Y ou must also meet the net worth and\n",
      "size limitations applicable to awards of administrative and\n",
      "litigation costs under section 7430; for individuals, this.......\n",
      "---\n",
      "## Document 4: 943-X, 944-X, or 945-X) if you’re also adjusting your\n",
      "tax liability. If you’re only adjusting your deposits in re-\n",
      "sponse to an FTD penalty notice, see the Instructions\n",
      "for Schedule B (Form 941), the Instructions for Form\n",
      "943-A (for Form 943), or the Instructions for Form\n",
      "945-A (for Forms 944 and 945).\n",
      "In addition to civil penalties, you may be subject to\n",
      "criminal prosecution (brought to trial) for willfully:\n",
      "•Evading tax;\n",
      "•Failing to collect or truthfully account for and pay over\n",
      "tax;\n",
      "•Failing to file a return, supply information, or pay any\n",
      "tax due;\n",
      "•Furnishing false or fraudulent Forms W-2 to employ-\n",
      "ees or failing to furnish Forms W-2;\n",
      "•Committing fraud and providing false statements;\n",
      "•Preparing and filing a fraudulent return; or\n",
      "•Committing identity theft.\n",
      "CAUTION!12. Filing Form 941, Form 943,\n",
      "Form 944, or Form 945\n",
      "Form 941.  If you paid wages subject to federal income\n",
      "tax withholding (including withholding on sick pay and.......\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the relevant documents, it's time to use the LLM to generate an answer based on these documents. \n",
    "\n",
    "We will take our initial prompt, together with our relevant documents which were retrieved based on the results of our similarity search. We combine these to create a prompt that we feed back to the model to get our result. At this point our model should give us highly informed information about whether we could be sent to jail for failing to file taxes.\n",
    "\n",
    "LangChain provides an abstraction of how this can be done easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick way\n",
    "You have the possibility to use the wrapper provided by LangChain which wraps around the Vector Store and takes input the LLM.\n",
    "This wrapper performs the following steps behind the scences:\n",
    "- Take the question as input\n",
    "- Create question embedding\n",
    "- Fetch relevant documents\n",
    "- Stuff the documents and the question into a prompt\n",
    "- Invoke the model with the prompt and generate an answer in a human-readable format"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:03:15.081675Z",
     "start_time": "2024-05-01T19:03:15.068017Z"
    }
   },
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:04:01.703627Z",
     "start_time": "2024-05-01T19:03:56.933367Z"
    }
   },
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore_faiss.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "answer = qa.invoke({\"query\": query})\n",
    "print_ww(answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Will I go to jail if I fail to file my taxes?', 'result': ' Based on the context\n",
      "provided, the penalties for failing to file Form 8300 can include fines up to $250,000 and up to 5\n",
      "years in prison for individuals. However, the context does not specify the penalties for failing to\n",
      "file a tax return in general. So I cannot conclusively state whether you would go to jail for\n",
      "failing to file your taxes without more specifics on the type of tax return and situation. The\n",
      "penalties seem to focus more on civil fines for late filing or failure to pay taxes owed. But\n",
      "criminal penalties like jail time could potentially apply in cases of more intentional or egregious\n",
      "tax evasion.', 'source_documents': [Document(page_content='There are civil penalties for failure\n",
      "to:\\nFile a correct Form 8300 by the date it is \\ndue, and\\nProvide the required statement to those\n",
      "\\nnamed in the Form 8300.\\nIf you intentionally disregard the requirement \\nto file a correct Form\n",
      "8300 by the date it is due, \\nthe penalty is the greater of:\\n1.$25,000, or\\n2.The amount of cash\n",
      "you received and \\nwere required to report (up to $100,000).\\nThere are criminal penalties\n",
      "for:\\nWillful failure to file Form 8300,\\nWillfully filing a false or fraudulent Form\n",
      "\\n8300,\\nStopping or trying to stop Form 8300 from \\nbeing filed, and\\nSetting up, helping to set\n",
      "up, or trying to \\nset up a transaction in a way that would \\nmake it seem unnecessary to file Form\n",
      "\\n8300.\\nIf you willfully fail to file Form 8300, you can \\nbe fined up to $250,000 for individuals\n",
      "\\nRECORDS($500,000 for corporations) or sentenced to up \\nto 5 years in prison, or both. These\n",
      "dollar \\namounts are based on Section 3571 of Title 18 \\nof the U.S. Code.', metadata={'source':\n",
      "'data/p1544.pdf', 'page': 3}), Document(page_content=\"ure-to- pay (FTP) penalty of 0.5% per month of\n",
      "the amount \\nof tax. For individual filers only, the FTP penalty is reduced \\nfrom 0.5% per month to\n",
      "0.25% per month if an installment \\nagreement is in effect. Y ou must have filed your return on \\nor\n",
      "before the due date of the return to qualify for the re-\\nduced penalty. The maximum amount of the\n",
      "FTP penalty \\nis also 25% of the tax due. If both penalties apply in any \\nmonth, the FTF penalty is\n",
      "reduced by the amount of the \\nFTP penalty. The penalties won't be charged if you have \\nreasonable\n",
      "cause for failing to file or pay. If you receive a \\npenalty notice, you can provide an explanation\n",
      "of why you \\nbelieve reasonable cause exists.\\nNote.  In addition to any penalties, interest accrues\n",
      "\\nfrom the due date of the tax on any unpaid balance.\\nIf income, social security, or Medicare taxes\n",
      "that must \\nbe withheld aren't withheld or aren't paid, you may be per-\\nsonally liable for the\n",
      "trust fund recovery penalty. See T rust\", metadata={'source': 'data/p15.pdf', 'page': 36}),\n",
      "Document(page_content=\"the exceptions to the deposit requirements discussed un-\\nder Payment with\n",
      "return , earlier in this section).\\nPenalties may apply if you don't make required deposits \\non\n",
      "time or if you make deposits for less than the required \\namount. The penalties don't apply if any\n",
      "failure to make a \\nproper and timely deposit was due to reasonable cause \\nand not to willful\n",
      "neglect. If you receive a penalty notice, \\nyou can provide an explanation of why you believe\n",
      "reason-\\nable cause exists.\\nIf you timely filed your employment tax return, the IRS \\nmay also\n",
      "waive deposit penalties if you inadvertently failed \\nto deposit and it was the first quarter that\n",
      "you were re-\\nquired to deposit any employment tax, or if you inadver-\\ntently failed to deposit the\n",
      "first time after your deposit fre-\\nquency changed. Y ou must also meet the net worth and \\nsize\n",
      "limitations applicable to awards of administrative and \\nlitigation costs under section 7430; for\n",
      "individuals, this\", metadata={'source': 'data/p15.pdf', 'page': 33})]}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask a different question:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:07:28.708042Z",
     "start_time": "2024-05-01T19:07:28.703768Z"
    }
   },
   "source": [
    "query_2 = \"What is the difference between market discount and qualified stated interest\""
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:07:47.637436Z",
     "start_time": "2024-05-01T19:07:43.032350Z"
    }
   },
   "source": [
    "answer_2  =answer = qa.invoke({\"query\": query_2})\n",
    "print_ww(answer_2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the difference between market discount and qualified stated interest', 'result':\n",
      "\" Based on the context provided:\\n\\nMarket discount is the difference between the issue price plus\n",
      "accrued OID and your adjusted basis, when your adjusted basis was less than the debt instrument's\n",
      "issue price plus the total OID that accrued before you acquired it. \\n\\nQualified stated interest is\n",
      "stated interest that is unconditionally payable in cash or property (other than debt instruments of\n",
      "the issuer) at least annually.\\n\\nSo the key difference is that market discount refers to the\n",
      "discount on the purchase price of a debt instrument compared to its issue price plus accrued OID,\n",
      "while qualified stated interest refers to regular interest payments made on the debt instrument.\n",
      "Market discount is a discount on the purchase price, while qualified stated interest is regular\n",
      "interest income paid to the holder.\", 'source_documents': [Document(page_content=\"was less than the\n",
      "debt instrument's issue price \\nplus the total OID that accrued before you ac-\\nquired it. The\n",
      "market discount is the difference \\nbetween the issue price plus accrued OID and \\nyour adjusted\n",
      "basis.\\nPremium. A debt instrument is purchased at a \\npremium if its adjusted basis immediately\n",
      "after \\npurchase is greater than the total of all amounts \\npayable on the debt instrument after the\n",
      "pur-\\nchase date, other than qualified stated interest. \\nThe premium is the excess of the adjusted\n",
      "ba-\\nsis over the payable amounts.\\nPremium will generally eliminate the future \\nreporting of OID\n",
      "in income by the purchaser, as \\ndiscussed under Information for Owners of OID \\nDebt Instruments ,\n",
      "later. See Pub. 550  for more \\ninformation on the tax treatment of bond pre-\\nmium.\\nQualified\n",
      "stated interest.  In general, qualified \\nstated interest is stated interest that is\n",
      "uncondi-\\ntionally payable in cash or property (other than \\ndebt instruments of the issuer) at\n",
      "least annually\", metadata={'source': 'data/p1212.pdf', 'page': 2}), Document(page_content='ket\n",
      "discount includible in income in box 5 of \\nForm 1099 -OID if you notify your broker in writ-\\ning\n",
      "that you elect to include market discount in \\nincome as it accrues. Unless you notify your \\nbroker\n",
      "in writing that you have not elected to \\nuse a constant yield method under section \\n1276(b) to\n",
      "determine accruals of market dis-\\ncount, your broker will use a constant yield \\nmethod to\n",
      "determine accruals of market dis-\\ncount rather than a ratable method.\\nSee Market Discount Bonds\n",
      "in chapter 1 of \\nPub. 550  for information on how to figure ac-\\ncrued market discount and include\n",
      "it in your in-\\ncome currently and for other information about \\nmarket discount bonds.\\nIf you\n",
      "choose to use the constant yield \\nmethod to figure accrued market discount, also \\nsee Figuring OID\n",
      "on Long -T erm Debt Instru-\\nments , later. The constant yield method of figur-\\ning accrued OID,\n",
      "explained under Debt Instru-\\nments Issued After July 1, 1982, and Before \\n1985  or Debt\n",
      "Instruments Issued After 1984 , as', metadata={'source': 'data/p1212.pdf', 'page': 5}),\n",
      "Document(page_content='(weighted average of accepted auction bids) \\ndiscount price for the longest\n",
      "-maturity T-bill ma-\\nturing on the same date as the T -bill being re-\\ndeemed. This noncompetitive\n",
      "discount price is \\nthe issue price (expressed as a percent of prin-\\ncipal) shown in Section\n",
      "III-A.\\nA similar rule is used to figure the discount \\non short- term discount obligations issued\n",
      "by the \\norganizations listed in Section III -B through \\nSection III-F .\\nExample 1.  There are 13\n",
      "-week and \\n26-week T -bills maturing on the same date as \\nthe T -bill being redeemed. The price\n",
      "actually \\npaid by the owner cannot be established by \\nowner or middleman records. Y ou treat as\n",
      "the \\nissue price of the T -bill the noncompetitive dis-\\ncount price (expressed as a percent of\n",
      "princi-\\npal) shown in Section III -A for a 26 -week bill \\nmaturing on the same date as the T -bill\n",
      "re-\\ndeemed. The interest you report on Form \\n1099- INT is the OID (per $1,000 of principal)\n",
      "\\nshown in Section III-A for that obligation.', metadata={'source': 'data/p1212.pdf', 'page': 3})]}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customisable option\n",
    "In the above scenario you explored the quick and easy way to get a context-aware answer to your question. Now let's have a look at a more customizable option with the help of [RetrievalQA](https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html) where you can customize how the documents are fetched and how they should be added to prompt using `chain_type` parameter. Also, if you want to control how many relevant documents should be retrieved then change the `k` parameter in the cell below to see different outputs. In many scenarios you might want to know which were the source documents that the LLM used to generate the answer, you can get those documents in the output using `return_source_documents` which returns the documents that are added to the context of the LLM prompt. `RetrievalQA` also allows you to provide a custom [prompt template](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html) which can be specific to the model.\n",
    "\n",
    "Note: In this example we are using Anthropic Claude as the LLM under Amazon Bedrock. This particular model [performs best](https://docs.anthropic.com/claude/docs/human-and-assistant-formatting) if the inputs are provided under `Human:` and the model is requested to generate an output after `Assistant:`. In the cell below you see an example of how to control the prompt such that the LLM stays grounded and doesn't answer outside the context."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:11:13.456795Z",
     "start_time": "2024-05-01T19:11:08.547377Z"
    }
   },
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore_faiss.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "query = \"Can I get sent to jail for failing to file my taxes?\"\n",
    "result = qa.invoke({\"query\": query})\n",
    "print_ww(result['result'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, yes, there are criminal penalties for willfully failing to file Form\n",
      "8300, which can result in fines up to $250,000 for individuals ($500,000 for corporations) or being\n",
      "sentenced to up to 5 years in prison, or both. The criminal penalties apply to willfully failing to\n",
      "file the form, willfully filing a false or fraudulent form, stopping or trying to stop the form from\n",
      "being filed, or setting up transactions to try to avoid having to file the form. Simply failing to\n",
      "file taxes does not appear to carry criminal penalties from the information given, though civil\n",
      "penalties like fines can apply.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-01T19:11:37.925385Z",
     "start_time": "2024-05-01T19:11:37.920193Z"
    }
   },
   "source": [
    "result['source_documents']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='There are civil penalties for failure to:\\nFile a correct Form 8300 by the date it is \\ndue, and\\nProvide the required statement to those \\nnamed in the Form 8300.\\nIf you intentionally disregard the requirement \\nto file a correct Form 8300 by the date it is due, \\nthe penalty is the greater of:\\n1.$25,000, or\\n2.The amount of cash you received and \\nwere required to report (up to $100,000).\\nThere are criminal penalties for:\\nWillful failure to file Form 8300,\\nWillfully filing a false or fraudulent Form \\n8300,\\nStopping or trying to stop Form 8300 from \\nbeing filed, and\\nSetting up, helping to set up, or trying to \\nset up a transaction in a way that would \\nmake it seem unnecessary to file Form \\n8300.\\nIf you willfully fail to file Form 8300, you can \\nbe fined up to $250,000 for individuals \\nRECORDS($500,000 for corporations) or sentenced to up \\nto 5 years in prison, or both. These dollar \\namounts are based on Section 3571 of Title 18 \\nof the U.S. Code.', metadata={'source': 'data/p1544.pdf', 'page': 3}),\n",
       " Document(page_content=\"ure-to- pay (FTP) penalty of 0.5% per month of the amount \\nof tax. For individual filers only, the FTP penalty is reduced \\nfrom 0.5% per month to 0.25% per month if an installment \\nagreement is in effect. Y ou must have filed your return on \\nor before the due date of the return to qualify for the re-\\nduced penalty. The maximum amount of the FTP penalty \\nis also 25% of the tax due. If both penalties apply in any \\nmonth, the FTF penalty is reduced by the amount of the \\nFTP penalty. The penalties won't be charged if you have \\nreasonable cause for failing to file or pay. If you receive a \\npenalty notice, you can provide an explanation of why you \\nbelieve reasonable cause exists.\\nNote.  In addition to any penalties, interest accrues \\nfrom the due date of the tax on any unpaid balance.\\nIf income, social security, or Medicare taxes that must \\nbe withheld aren't withheld or aren't paid, you may be per-\\nsonally liable for the trust fund recovery penalty. See T rust\", metadata={'source': 'data/p15.pdf', 'page': 36}),\n",
       " Document(page_content='you may owe a penalty unless you have reasonable \\ncause. See Pub. 1586, Reasonable Cause Regulations & \\nCAUTION!\\nCAUTION!\\nPublication 15 (2024) 15', metadata={'source': 'data/p15.pdf', 'page': 14})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this module on retrieval augmented generation! This is an important technique that combines the power of large language models with the precision of retrieval methods. By augmenting generation with relevant retrieved examples, the responses we received become more coherent, consistent and grounded. You should feel proud of learning this innovative approach. I'm sure the knowledge you've gained will be very useful for building creative and engaging language generation systems. Well done!\n",
    "\n",
    "In the above implementation of RAG based Question Answering we have explored the following concepts and how to implement them using Amazon Bedrock and its LangChain integration.\n",
    "\n",
    "- Loading documents and generating embeddings to create a vector store\n",
    "- Retrieving documents to the question\n",
    "- Preparing a prompt which goes as input to the LLM\n",
    "- Present an answer in a human friendly manner\n",
    "\n",
    "### Take-aways\n",
    "- Experiment with different Vector Stores\n",
    "- Leverage various models available under Amazon Bedrock to see alternate outputs\n",
    "- Explore options such as persistent storage of embeddings and document chunks\n",
    "- Integration with enterprise data stores\n",
    "\n",
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "ragtestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
