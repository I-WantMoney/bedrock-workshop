{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3f88dd-0f5e-427e-84ee-8934982300d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# コンテキストを含むプロンプトを使用する LangChainに よる Bedrock\n",
    "\n",
    "> *この ノートブック は SageMaker Studio の **`Data Science 3.0`** カーネルをご利用ください*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920ca4a-a71d-4630-a6e4-577d95192ad1",
   "metadata": {},
   "source": [
    "## 導入\n",
    "\n",
    "このノートブックでは、カスタマーサポートエンジニアから受けたカスタマーサービスの質に満足していない顧客へのメール返信を生成する方法を説明します。不満を抱いている顧客から受信した実際のメールの内容を提供することで、モデルに追加のコンテキストを提供します。\n",
    "\n",
    "プロンプトにはコンテキストが追加されているため、このノートブックの Amazon Titan Text Large モデルによって生成されたテキストは、以前に Zero-Shot プロンプトで作成されたコンテンツよりも品質と関連性がはるかに優れています。\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html) は、言語モデルを利用したアプリケーションを開発するためのフレームワークです。このフレームワークの主な特徴により、さまざまなコンポーネントを連結して高度なユースケースを作成することで、大規模言語モデルを拡張できます。\n",
    "\n",
    "このノートブックでは、LangChain が提供する Bedrock API を使用します。この例で使用されているプロンプトは、テキスト生成リクエストにコンテキストを追加するためのカスタム LangChain プロンプトテンプレートを作成します。 \n",
    "\n",
    "**Note:** *このノートブックは AWS 内外問わず実行することができます*\n",
    "\n",
    "#### コンテキスト\n",
    "先ほどの `01_zero_shot_generation.ipynb` の例では、LangChain フレームワークを使用して Amazon Bedrock API と通信する方法について説明しました。このノートブックでは、`PromptTemplate` を使用して、LangChain フレームワークを同様のユースケースで利用できるようにもう少し複雑さを加えようとします。`PromptTemplate` を使うと、後で情報を入力できる汎用シェルを作成したり、さまざまなシナリオに基づいてモデル出力を取得したりできます。\n",
    "\n",
    "このノートブックの中で、LangChain フレームワーク内の Amazon Bedrock 統合の使用方法と、それを使用して `PromptTemplate` を使用してテキストを生成する方法を探ります。\n",
    "\n",
    "#### パターン\n",
    "Amazon Bedrock API の LangChain 実装に、タスク、命令、入力を提供するだけで、追加の例は示さずに出力を生成できます。ここでの目的は、強力な LLM が目の前のタスクをいかに簡単に理解し、説得力のある出力を生成するかを示すことです。\n",
    "\n",
    "![](./images/bedrock_langchain.jpg)\n",
    "\n",
    "#### ユースケース\n",
    "Amazon Bedrock のモデルの生成機能を実証するために、E メール生成のユースケースを見てみましょう。\n",
    "\n",
    "#### ペルソナ\n",
    "あなたは AnyCompany のカスタマーサービスマネージャーである Bob ですが、一部の顧客はカスタマーサービスに満足しておらず、カスタマーサポートエンジニアが提供するサービスに否定的なフィードバックをしています。今度は、サービスの質が悪かったことを謙虚に謝罪する顧客に応え、信頼を取り戻したいと考えています。以前のメールでのやり取りから得た顧客の感情に合わせて、ヒューマンフレンドリーなメールを大量に生成するには、LLM の助けが必要です。\n",
    "\n",
    "#### 実装\n",
    "このユースケースを実現するために、顧客の以前のメールに基づいてサンキューノート付きのメールを生成する方法を紹介します。ここでは Amazon Bedrock LangChain インテグレーションを使用する Amazon Titan Text Large モデルを使用します。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11828a-243d-4808-9c92-e8caf4cebd37",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "このノートブックの以降を実行する前に、以下のセルを実行して (必要なライブラリがインストールされていることを確認し) Bedrockに接続する必要があります。\n",
    "\n",
    "セットアップの仕組みと ⚠️ **変更の要否** の詳細については [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb) を参照ください。\n",
    "\n",
    "このノートブックには、入力プロンプト内のトークンの数をカウントするために使用する [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) ライブラリもインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e2c0a9-4838-4f2b-bb36-61c0cbcd62af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 事前にリポジトリルートから `download-dependencies.sh` を実行済みであることを確認してください!\n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    ../dependencies/awscli-*-py3-none-any.whl \\\n",
    "    ../dependencies/boto3-*-py3-none-any.whl \\\n",
    "    ../dependencies/botocore-*-py3-none-any.whl\n",
    "\n",
    "%pip install --quiet langchain==0.0.249 \"transformers>=4.24,<5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a9372-0789-414a-a1d7-2976056f2015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ 必要に応じて AWS 設定に関する以下のコードのコメントを解除、編集してください ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7daa1a8-d21a-410c-adbf-b253c2dabf80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LangChain インテグレーションを使用して Bedrock クライアントを起動\n",
    "\n",
    "llms から Bedrock クラスのインスタンスを作成することから始めましょう。これは Amazon Bedrock で利用できるモデルの `model_id` を想定しています。 \n",
    "\n",
    "オプションで、以前に作成した boto3 の `client` のほか、`temperature`、`topP`、`maxTokenCount`、`stopSequences` などのパラメータを保持できる `model_kwargs` を渡すことができます (パラメータの詳細については Amazon Bedrock コンソールで確認できます)。\n",
    "\n",
    "Amazon Bedrock で利用可能なテキスト生成モデルには、次の ID があります。\n",
    "\n",
    "- `amazon.titan-tg1-large`\n",
    "- `ai21.j2-grande-instruct`\n",
    "- `ai21.j2-jumbo-instruct`\n",
    "- `anthropic.claude-instant-v1`\n",
    "- `anthropic.claude-v1`\n",
    "\n",
    "`model_kwargs` はモデルが異なればサポートも異なることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa1250-56cd-4b6d-b3d8-c62baac143ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":0.5,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v1\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2678ed-f0d6-444f-9a57-5170dd1952f7",
   "metadata": {},
   "source": [
    "## LangChain カスタムプロンプトテンプレートを作成\n",
    "\n",
    "プロンプトのテンプレートを作成することで、実行ごとに異なる入力変数を渡すことができます。これは、データベースから取得するさまざまな入力変数を使用してコンテンツを生成する必要がある場合に便利です。\n",
    "\n",
    "以前のラボではプロンプトをハードコーディングしていました。ここでは、複数の顧客が同様の否定的なフィードバックを送信していて、それらの顧客の各メールを使用して謝罪を返信したい場合であり、応答も少しパーソナライズしておきたい場合を想定します。次のセルでは、このパターンを実現するための `PromptTemplate` を作成する方法を検討しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec103a-97ae-4e9e-9d80-dc20f354a228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# 複数の入力変数を含むプロンプトテンプレートの作成\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"customerServiceManager\", \"customerName\", \"feedbackFromCustomer\"], \n",
    "    template=\"\"\"Create an apology email from the Service Manager {customerServiceManager} to {customerName}. \n",
    "   in response to the following feedback that was received from the customer: {feedbackFromCustomer}.\n",
    "   \"\"\"\n",
    ")\n",
    "\n",
    "# 入力変数に値を渡す\n",
    "prompt = multi_var_prompt.format(customerServiceManager=\"Bob\", \n",
    "                                 customerName=\"John Doe\", \n",
    "                                 feedbackFromCustomer=\"\"\"Hello Bob,\n",
    "     I am very disappointed with the recent experience I had when I called your customer support.\n",
    "     I was expecting an immediate call back but it took three days for us to get a call back.\n",
    "     The first suggestion to fix the problem was incorrect. Ultimately the problem was fixed after three days.\n",
    "     We are very unhappy with the response provided and may consider taking our business elsewhere.\n",
    "     \"\"\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bdfd5-ce76-42e9-81cd-b0892337d163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "print(f\"Our prompt has {num_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf31e9-56c0-408f-a652-9e23de446aef",
   "metadata": {},
   "source": [
    "## 再呼び出し\n",
    "\n",
    "プロンプトテンプレートを使用して起動すると、精選された応答が返されることが期待されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1064c57-27a4-48c5-911b-e4f1dfeff122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = textgen_llm(prompt)\n",
    "\n",
    "email = response[response.index('\\n')+1:]\n",
    "\n",
    "print_ww(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9abc40",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "結論として、[Zero-Shot](./01_zero_shot_generation.ja.ipynb) プロンプトによりコンテキストなしで LLM を呼び出しても、望ましい結果が得られない可能性があることがわかりました。コンテキストを追加し、さらに prompt テンプレートを使用して LLM からの出力を制限することで、目的の出力を正常に得ることができます。"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
